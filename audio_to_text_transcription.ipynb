{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOaOrudZ+ucqliA/JApvHA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrotich-github/vrotich-github/blob/main/audio_to_text_transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unh1f3vLy0L-",
        "outputId": "33ab8c5f-3fbf-4a68-b9f6-9ea3abf6686e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.14.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Downloading SpeechRecognition-3.14.0-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.0 pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyannote.audio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wBk0r6kekBsj",
        "outputId": "723b2320-84cd-43b1-e9dd-c6c65ffddeb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyannote.audio\n",
            "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio)\n",
            "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.8.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.27.0)\n",
            "Collecting lightning>=2.0.1 (from pyannote.audio)\n",
            "  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<3.0,>=2.1 (from pyannote.audio)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pyannote.core>=5.0.0 (from pyannote.audio)\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyannote.database>=5.0.1 (from pyannote.audio)\n",
            "  Downloading pyannote.database-5.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyannote.metrics>=3.2 (from pyannote.audio)\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio)\n",
            "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
            "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (13.9.4)\n",
            "Collecting semver>=3.0.0 (from pyannote.audio)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.12.1)\n",
            "Collecting speechbrain>=1.0.0 (from pyannote.audio)\n",
            "  Downloading speechbrain-1.0.2-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting tensorboardX>=2.6 (from pyannote.audio)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.5.1+cu121)\n",
            "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio)\n",
            "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torchaudio>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.5.1+cu121)\n",
            "Collecting torchmetrics>=0.11.0 (from pyannote.audio)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote.audio)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio)\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote.audio)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sortedcontainers>=2.0.4 (from pyannote.core>=5.0.0->pyannote.audio)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.13.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.15.1)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.6.0)\n",
            "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.8.0)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.13.1)\n",
            "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio) (2.18.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
            "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.4.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.6->pyannote.audio) (4.25.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.11.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (75.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.8.2)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.36)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.5.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.18.3)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.1.1)\n",
            "Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
            "Downloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.database-5.1.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Downloading speechbrain-1.0.2-py3-none-any.whl (824 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, docopt, julius\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=5ac6c0e99e24a0319ac19785b25ad0e7880ef1812a6c2191012442aefbae68bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=bd2117d56f30e1a2af5b00aab08bdfe09b771c2c5984c669dab27836af916b3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21869 sha256=17cf89ac1400462fc49900619a598d879d2b8bd2addfe0bb0993b45db81a76ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n",
            "Successfully built antlr4-python3-runtime docopt julius\n",
            "Installing collected packages: sortedcontainers, primePy, docopt, antlr4-python3-runtime, tensorboardX, semver, ruamel.yaml.clib, omegaconf, Mako, lightning-utilities, colorlog, ruamel.yaml, pyannote.core, alembic, torchmetrics, pytorch-metric-learning, optuna, julius, hyperpyyaml, asteroid-filterbanks, torch-pitch-shift, speechbrain, pyannote.database, torch-audiomentations, pytorch-lightning, pyannote.pipeline, pyannote.metrics, lightning, pyannote.audio\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 colorlog-6.9.0 docopt-0.6.2 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.5.0.post0 lightning-utilities-0.11.9 omegaconf-2.3.0 optuna-4.1.0 primePy-1.3 pyannote.audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.1 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.5.0.post0 pytorch-metric-learning-2.8.1 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 semver-3.0.2 sortedcontainers-2.4.0 speechbrain-1.0.2 tensorboardX-2.6.2.2 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchmetrics-1.6.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "07697ac1f5fe4c4b9176e51667b116a3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing libraries\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence"
      ],
      "metadata": {
        "id": "LusGC6bRzxJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/Speaker26_000.wav\""
      ],
      "metadata": {
        "id": "Gxk0HtXJ1QMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = sr.Recognizer()\n",
        "\n",
        "audio_file = sr.AudioFile('/content/TranscriptionStaff (3).mp3')\n",
        "\n",
        "# extract all utterances from the response\n",
        "utterances = audio_file.utterances\n",
        "\n",
        "# For each utterance, print its speaker and what was said\n",
        "for utterance in utterances:\n",
        "  speaker = utterance.speaker\n",
        "  text = utterance.text\n",
        "  print(f\"Speaker {speaker}: {text}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "ILnH2v8tz7gI",
        "outputId": "39273b77-199c-4f01-89d9-225720b62adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'AudioFile' object has no attribute 'utterances'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-069eb426b480>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# extract all utterances from the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mutterances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutterances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# For each utterance, print its speaker and what was said\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'AudioFile' object has no attribute 'utterances'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a function to recognize speech in the audio file\n",
        "# so that we don't repeat ourselves in in other functions\n",
        "def transcribe_audio(path):\n",
        "    # use the audio file as the audio source\n",
        "    with sr.AudioFile(path) as source:\n",
        "        audio_listened = r.record(source)\n",
        "        # try converting it to text\n",
        "        text = r.recognize_google(audio_listened)\n",
        "    return text\n",
        "def process_audio_to_chunks(path):\n",
        "    \"\"\"Splitting the large audio file into chunks\n",
        "    and apply speech recognition on each of these chunks\"\"\"\n",
        "    # open the audio file using pydub\n",
        "    sound = AudioSegment.from_file(path)\n",
        "    # split audio sound where silence is 500 miliseconds or more and get chunks\n",
        "    chunks = split_on_silence(sound,\n",
        "        # experiment with this value for your target audio file\n",
        "        min_silence_len = 500,\n",
        "        # adjust this per requirement\n",
        "        silence_thresh = sound.dBFS-14,\n",
        "        # keep the silence for 1 second, adjustable as well\n",
        "        keep_silence=500,\n",
        "    )\n",
        "    folder_name = \"audio-chunks\"\n",
        "    # create a directory to store the audio chunks\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    whole_text = \"\"\n",
        "    # process each chunk\n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        # export audio chunk and save it in\n",
        "        # the `folder_name` directory.\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "        # recognize the chunk\n",
        "        try:\n",
        "            text = transcribe_audio(chunk_filename)\n",
        "        except sr.UnknownValueError as e:\n",
        "            print(\"Error:\", str(e))\n",
        "        else:\n",
        "            text = f\"{text.capitalize()}. \"\n",
        "            print(chunk_filename, \":\", text)\n",
        "            whole_text += text\n",
        "    # return the text for all chunks detected\n",
        "    return whole_text"
      ],
      "metadata": {
        "id": "yblN1t6m3LAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_large_audio_transcription_on_silence(path):\n",
        "    \"\"\"Splitting the large audio file into chunks\n",
        "    and apply speech recognition on each of these chunks\"\"\"\n",
        "    # load the audio file using pydub\n",
        "    sound = AudioSegment.from_file(path, chunk_length_ms=500)\n",
        "    # split audio sound where silence is 500 miliseconds or more and get chunks\n",
        "    chunks = split_on_silence(sound,\n",
        "        # experiment with this value for your target audio file\n",
        "        min_silence_len = 500,\n",
        "        # adjust this per requirement\n",
        "        silence_thresh = sound.dBFS-14,\n",
        "        # keep the silence for 1 second, adjustable as well\n",
        "        keep_silence=500,\n",
        "    )\n",
        "    folder_name = \"audio-chunks\"\n",
        "    # create a directory to store the audio chunks\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    whole_text = \"\"\n",
        "    # process each chunk\n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        # export audio chunk and save it in\n",
        "        # the `folder_name` directory.\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "        # recognize the chunk\n",
        "        try:\n",
        "            text = transcribe_audio(chunk_filename)\n",
        "        except sr.UnknownValueError as e:\n",
        "            print(\"Error:\", str(e))\n",
        "        else:\n",
        "            text = f\"{text.capitalize()}. \"\n",
        "            print(chunk_filename, \":\", text)\n",
        "            whole_text += text\n",
        "    # return the text for all chunks detected\n",
        "    return whole_text"
      ],
      "metadata": {
        "id": "dQKSbL5-31mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFull text:\", get_large_audio_transcription_on_silence(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU9fJQeV4FLJ",
        "outputId": "8986e98e-02b3-4187-f702-f2a26bc9052b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio-chunks/chunk1.wav : Section 0 of aesop's fables a new revised version by aes. \n",
            "audio-chunks/chunk2.wav : This sleeper box recording is in the public domain. \n",
            "audio-chunks/chunk3.wav : Preface. \n",
            "audio-chunks/chunk4.wav : The following are some of aesop's best loved fables. \n",
            "audio-chunks/chunk5.wav : The goose with the golden eggs. \n",
            "audio-chunks/chunk6.wav : A certain man had the good fortune to possess a goose that laid him a golden egg everyday. \n",
            "audio-chunks/chunk7.wav : Go to satisfied with so slow and income and thinking to seize the whole treasure at once. \n",
            "audio-chunks/chunk8.wav : He killed a goose and cutting her open. \n",
            "audio-chunks/chunk9.wav : Found her just what any other goose would be. \n",
            "audio-chunks/chunk10.wav : Much wants more and loses all. \n",
            "audio-chunks/chunk11.wav : The town mouse and the country mouse. \n",
            "audio-chunks/chunk12.wav : A country mouse invited a town mouse and intimate friend. \n",
            "audio-chunks/chunk13.wav : To pay him a visit in partake of his country fair. \n",
            "audio-chunks/chunk14.wav : As they were on the bear plowed lands eating their. \n",
            "\n",
            "Full text: Section 0 of aesop's fables a new revised version by aes. This sleeper box recording is in the public domain. Preface. The following are some of aesop's best loved fables. The goose with the golden eggs. A certain man had the good fortune to possess a goose that laid him a golden egg everyday. Go to satisfied with so slow and income and thinking to seize the whole treasure at once. He killed a goose and cutting her open. Found her just what any other goose would be. Much wants more and loses all. The town mouse and the country mouse. A country mouse invited a town mouse and intimate friend. To pay him a visit in partake of his country fair. As they were on the bear plowed lands eating their. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "\n",
        "def transcribe_audio(path):\n",
        "    \"\"\"Transcribes a single audio file.\"\"\"\n",
        "    r = sr.Recognizer()  # Initialize recognizer within the function\n",
        "    with sr.AudioFile(path) as source:\n",
        "        audio = r.record(source)\n",
        "        try:\n",
        "            text = r.recognize_google(audio)\n",
        "        except sr.UnknownValueError:\n",
        "            return \"\"  # Return empty string on error\n",
        "        else:\n",
        "            return text\n",
        "\n",
        "def get_large_audio_transcription_on_silence(path):\n",
        "    \"\"\"Splits a large audio file into chunks based on silence\n",
        "    and transcribes each chunk.\"\"\"\n",
        "    sound = AudioSegment.from_file(path)\n",
        "    chunks = split_on_silence(sound,\n",
        "        min_silence_len=500,\n",
        "        silence_thresh=sound.dBFS - 14,\n",
        "        keep_silence=500\n",
        "    )\n",
        "    folder_name = \"audio-chunks\"\n",
        "    os.makedirs(folder_name, exist_ok=True)  # Create folder if it doesn't exist\n",
        "\n",
        "    whole_text = \"\"\n",
        "    for i, chunk in enumerate(chunks, 1):\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "        text = transcribe_audio(chunk_filename)\n",
        "        if text:  # Check if transcription was successful\n",
        "            text = f\"{text.capitalize()}. \"\n",
        "            print(f\"{chunk_filename}: {text}\")\n",
        "            whole_text += text\n",
        "\n",
        "    return whole_text\n",
        "\n",
        "# Example usage:\n",
        "path = \"/content/Speaker26_000.wav\"  # Replace with your audio file path\n",
        "print(\"\\nFull text:\", get_large_audio_transcription_on_silence(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb0UNkfsA0RM",
        "outputId": "664ef88f-912a-4e2a-9260-60cbd6796485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio-chunks/chunk1.wav: Section 0 of aesop's fables a new revised version by aes. \n",
            "audio-chunks/chunk2.wav: This sleeper box recording is in the public domain. \n",
            "audio-chunks/chunk3.wav: Preface. \n",
            "audio-chunks/chunk4.wav: The following are some of aesop's best loved fables. \n",
            "audio-chunks/chunk5.wav: The goose with the golden eggs. \n",
            "audio-chunks/chunk6.wav: A certain man had the good fortune to possess a goose that laid him a golden egg everyday. \n",
            "audio-chunks/chunk7.wav: Go to satisfied with so slow and income and thinking to seize the whole treasure at once. \n",
            "audio-chunks/chunk8.wav: He killed a goose and cutting her open. \n",
            "audio-chunks/chunk9.wav: Found her just what any other goose would be. \n",
            "audio-chunks/chunk10.wav: Much wants more and loses all. \n",
            "audio-chunks/chunk11.wav: The town mouse and the country mouse. \n",
            "audio-chunks/chunk12.wav: A country mouse invited a town mouse and intimate friend. \n",
            "audio-chunks/chunk13.wav: To pay him a visit in partake of his country fair. \n",
            "audio-chunks/chunk14.wav: As they were on the bear plowed lands eating their. \n",
            "\n",
            "Full text: Section 0 of aesop's fables a new revised version by aes. This sleeper box recording is in the public domain. Preface. The following are some of aesop's best loved fables. The goose with the golden eggs. A certain man had the good fortune to possess a goose that laid him a golden egg everyday. Go to satisfied with so slow and income and thinking to seize the whole treasure at once. He killed a goose and cutting her open. Found her just what any other goose would be. Much wants more and loses all. The town mouse and the country mouse. A country mouse invited a town mouse and intimate friend. To pay him a visit in partake of his country fair. As they were on the bear plowed lands eating their. \n"
          ]
        }
      ]
    }
  ]
}